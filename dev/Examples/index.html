<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Examples · Autologistic.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Autologistic.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Introduction</a></li><li><a class="toctext" href="../Background/">Background</a></li><li><a class="toctext" href="../Design/">Design of the Package</a></li><li><a class="toctext" href="../BasicUsage/">Basic Usage</a></li><li class="current"><a class="toctext" href>Examples</a><ul class="internal"><li><a class="toctext" href="#An-Ising-Model-1">An Ising Model</a></li><li><a class="toctext" href="#Clustered-Binary-Data-(Small-n)-1">Clustered Binary Data (Small <span>$n$</span>)</a></li><li><a class="toctext" href="#Spatial-Binary-Regression-1">Spatial Binary Regression</a></li></ul></li><li><a class="toctext" href="../api/">Reference</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Examples</a></li></ul><a class="edit-page" href="https://github.com/kramsretlow/Autologistic.jl/blob/master/docs/src/Examples.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Examples</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Examples-1" href="#Examples-1">Examples</a></h1><p>These examples demonstrate most of the functionality of the package, its typical usage, and how to make some plots you might want to use.</p><p>The examples:</p><ul><li><a href="#An-Ising-Model-1">An Ising Model</a> shows how to use the package to explore the autologistic probability distribution, without concern about covariates or parameter estimation.</li><li><a href="#Clustered-Binary-Data-(Small-n)-1">Clustered Binary Data (Small <span>$n$</span>)</a> shows how to use the package for regression analysis of correlated binary responses when the graph is small enough to permit computation of the normalizing constant.</li><li><a href="#Spatial-Binary-Regression-1">Spatial Binary Regression</a> shows how to use the package for autologistic regression analysis for larger, spatially-referenced graphs.</li></ul><h2><a class="nav-anchor" id="An-Ising-Model-1" href="#An-Ising-Model-1">An Ising Model</a></h2><p>The term &quot;Ising model&quot; is usually used to refer to a Markov random field of dichotomous random variables on a regular lattice.  The graph is such that each variable shares an edge only with its nearest neighbors in each dimension.  It&#39;s a traditional model for magnetic spins, where the coding <span>$(-1,1)$</span> is usually used. There&#39;s one parameter per vertex (a &quot;local magnetic field&quot;) that increases or decreases the chance of getting a <span>$+1$</span> state at that vertex; and there&#39;s a single pairwise parameter that controls the strength of interaction between neighbor states.</p><p>In our terminology it&#39;s just an autologistic model with the appropriate graph. Specifically, it&#39;s an <code>ARsimple</code> model: one with <code>FullUnary</code> type unary parameter, and <code>SimplePairwise</code> type pairwise parameter.</p><p>We can create such a model once we have the graph.  For example, let&#39;s create two 30-by-30 lattices: one without any special handling of the boundary, and one with periodic boundary conditions. This can be done with <a href="https://github.com/JuliaGraphs/LightGraphs.jl">LightGraphs.jl</a>&#39;s <code>Grid</code> function.</p><div><pre><code class="language-julia">n = 30  # numer of rows and columns
using LightGraphs
G1 = Grid([n, n], periodic=false)
G2 = Grid([n, n], periodic=true)</code></pre></div><p>Now create an AL model for each case. Initialize the unary parameters to Gaussian white noise. By default the pairwise parameter is set to zero, which implies independence of the variables. Use the same parameters for the two models, so the only difference betwen them is the graph.</p><div><pre><code class="language-julia">using Random, Autologistic
Random.seed!(8888)
α = randn(n^2)
M1 = ALsimple(G1, α)
M2 = ALsimple(G2, α)</code></pre><pre><code class="language-none">Autologistic model of type ALsimple with parameter vector [α; λ].
Fields:
  responses    900×1 Bool array
  unary        900×1 FullUnary with fields:
                 α  900×1 array (unary parameter values)
  pairwise     900×900×1 SimplePairwise with fields:
                 λ      [0.0] (association parameter)
                 G      the graph (900 vertices, 1800 edges)
                 count  1 (the number of observations)
                 A      900×900 SparseMatrixCSC (the adjacency matrix)
  centering    none
  coding       (-1, 1)
  labels       (&quot;low&quot;, &quot;high&quot;)
  coordinates  900-element vector of Tuple{Float64,Float64}</code></pre></div><p>The REPL output shows information about the model.  It&#39;s an <code>ALsimple</code> type with one observation of length 900.</p><p>The <code>conditionalprobabilities</code> function returns the probablity of observing a <span>$+1$</span> state at each vertex, conditional on the vertex&#39;s neighbor values. These can be visualized as an image, using a <code>heatmap</code> (from <a href="https://github.com/JuliaPlots/Plots.jl">Plots.jl</a>):</p><pre><code class="language-">using Plots
condprobs = conditionalprobabilities(M1)
hm = heatmap(reshape(condprobs, n, n), c=:grays, aspect_ratio=1,
             title=&quot;probability of +1 under independence&quot;)
plot(hm)</code></pre><p>Since the association parameter is zero, there are no neighborhood effects.  The above conditional probabilities are equal to the marginal probabilities.</p><p>Next, set the association parameters to 0.75, a fairly strong association level, to introduce a neighbor effect.</p><div><pre><code class="language-julia">setpairwiseparameters!(M1, [0.75])
setpairwiseparameters!(M2, [0.75])</code></pre></div><p>A quick way to see the effect of this parameter is to observe random samples from the models. The <code>sample</code> function can be used to do this. For this example, use perfect sampling using a bounding chain algorithm (the enumeration <a href="../api/#Autologistic.SamplingMethods"><code>SamplingMethods</code></a> lists the available sampling options).</p><div><pre><code class="language-julia">s1 = sample(M1, method=perfect_bounding_chain)
s2 = sample(M2, method=perfect_bounding_chain)</code></pre></div><p>The samples can also be visualized using <code>heatmap</code>:</p><pre><code class="language-">pl1 = heatmap(reshape(s1, n, n), c=:grays, colorbar=false, title=&quot;regular boundary&quot;);
pl2 = heatmap(reshape(s2, n, n), c=:grays, colorbar=false, title=&quot;periodic boundary&quot;);
plot(pl1, pl2, size=(800,400), aspect_ratio=1)</code></pre><p>In these plots, black indicates the low state, and white the high state.  A lot of local clustering is occurring in the samples due to the neighbor effects.</p><p>To see the long-run differences between the two models, we can look at the marginal probabilities. They can be estimated by drawing many samples and averaging them (note that running this code chunk can take a couple of minutes):</p><pre><code class="language-julia">marg1 = sample(M1, 500, method=perfect_bounding_chain, verbose=true, average=true)
marg2 = sample(M2, 500, method=perfect_bounding_chain, verbose=true, average=true)
pl3 = heatmap(reshape(marg1, n, n), c=:grays, colorbar=false, title=&quot;regular boundary&quot;);
pl4 = heatmap(reshape(marg2, n, n), c=:grays, colorbar=false, title=&quot;periodic boundary&quot;);
plot(pl3, pl4, size=(800,400), aspect_ratio=1)
savefig(&quot;marginal-probs.png&quot;)</code></pre><p>The figure <code>marginal-probs.png</code> looks like this:</p><p><img src="/assets/marginal-probs.png" alt/></p><p>Although the differences between the two marginal distributions are not striking, the extra edges connecting top to bottom and left to right do have some influence on the probabilities at the periphery of the square.</p><p>As a final demonstration, perform Gibbs sampling for model <code>M2</code>, starting from a random state.  Display a gif animation of the progress.</p><pre><code class="language-julia">nframes = 150
gibbs_steps = sample(M2, nframes, method=Gibbs)
anim = @animate for i =  1:nframes
    heatmap(reshape(gibbs_steps[:,i], n, n), c=:grays, colorbar=false, 
            aspect_ratio=1, title=&quot;Gibbs sampling: step $(i)&quot;)
end
gif(anim, &quot;ising_gif.gif&quot;, fps=10)</code></pre><p><img src="/assets/ising_gif.gif" alt/></p><h2><a class="nav-anchor" id="Clustered-Binary-Data-(Small-n)-1" href="#Clustered-Binary-Data-(Small-n)-1">Clustered Binary Data (Small <span>$n$</span>)</a></h2><p>The <em>retinitis pigmentosa</em> data set <a href="https://sites.google.com/a/channing.harvard.edu/bernardrosner/channing/regression-method-when-the-eye-is-the-unit-of-analysis">obtained here</a> is an opthalmology data set.  The data comes from 444 patients that had both eyes examined.  The data can be loaded with <code>Autologistic.datasets</code>:</p><pre><code class="language-julia-repl">julia&gt; using Autologistic, DataFrames, LightGraphs

julia&gt; df = Autologistic.datasets(&quot;pigmentosa&quot;);
ERROR: ArgumentError: &quot;/home/travis/build/kramsretlow/Autologistic.jl/src/../assets\pigmentosa.csv&quot; is not a valid file

julia&gt; first(df, 6)
ERROR: UndefVarError: df not defined

julia&gt; describe(df)
ERROR: UndefVarError: df not defined</code></pre><p>The response for each eye is <strong>va</strong>, an indicator of poor visual acuity (coded 0 = no, 1 = yes in the loaded data set). Seven covariates were also recorded for each eye:</p><ul><li><strong>aut_dom</strong>: autosomal dominant (0=no, 1=yes)</li><li><strong>aut_rec</strong>: autosomal recessive (0=no, 1=yes)</li><li><strong>sex_link</strong>: sex-linked (0=no, 1=yes)</li><li><strong>age</strong>: age (years, range 6-80)</li><li><strong>sex</strong>: gender (0=female, 1=male)</li><li><strong>psc</strong>: posterior subscapsular cataract (0=no, 1=yes)</li><li><strong>eye</strong>: which eye is it? (0=left, 1=right)</li></ul><p>The last four factors are relevant clinical observations, and the first three are genetic factors. The data set also includes an <strong>ID</strong> column with an ID number specific to each patient.  Eyes with the same ID come from the same person.</p><p>The natural unit of analysis is the eye, but pairs of observations from the same patient are &quot;clustered&quot; because the occurrence of acuity loss in the left and right eye is probably correlated. We can model each person&#39;s two eyes&#39; <strong>va</strong> outcomes as two dichotomous random variables with a 2-vertex, 1-edge graph.</p><div><pre><code class="language-julia">G = Graph(2,1)</code></pre><pre><code class="language-none">{2, 1} undirected simple Int64 graph</code></pre></div><p>Each of the 444 observations has this graph, and each has its own set of covariates.</p><p>If we include all seven predictors, plus intercept, in our model, we have 2 variables per observation, 8 predictors, and 444 obsrevations. </p><p>Before creating the model we need to re-structure the covariates. The data in <code>df</code> has one row per eye, with the variable <code>ID</code> indicating which eyes belong to the same patient.  We need to rearrange the responses (<code>Y</code>) and the predictors (<code>X</code>) into arrays suitable for our autologistic models, namely:</p><ul><li><code>Y</code> is <span>$2 \times 444$</span> with one observation per column.</li><li><code>X</code> is <span>$2 \times 8 \times 444$</span> with one <span>$2 \times 8$</span> matrix of predictors for each observation.  The first column of each predictor matrix is an intercept column, and   columns 2 through 8 are for <code>aut_dom</code>, <code>aut_rec</code>, <code>sex_link</code>, <code>age</code>, <code>sex</code>, <code>psc</code>, and <code>eye</code>, respectively.</li></ul><pre><code class="language-">X = Array{Float64,3}(undef, 2, 8, 444);
Y = Array{Float64,2}(undef, 2, 444);
for i in 1:2:888
    subject = Int((i+1)/2)
    X[1,:,subject] = [1 permutedims(Vector(df[i,2:8]))]
    X[2,:,subject] = [1 permutedims(Vector(df[i+1,2:8]))]
    Y[:,subject] = convert(Array, df[i:i+1, 9])
end</code></pre><p>For example, patient 100 had responses</p><div><pre><code class="language-julia">Y[:,100]</code></pre><pre><code class="language-none">2-element Array{Float64,1}:
 0.0
 0.0</code></pre></div><p>Indicating visual acuity loss in the left eye, but not in the right. The predictors for this individual are</p><div><pre><code class="language-julia">X[:,:,100]</code></pre><pre><code class="language-none">2×8 Array{Float64,2}:
 NaN             2.122e-314  2.79666e-316  …  1.061e-314   NaN
   2.79664e-316  1.061e-314  6.36599e-314     2.7967e-316    2.122e-314</code></pre></div><p>Now we can create our autologistic regression model.</p><pre><code class="language-">model = ALRsimple(G, X, Y=Y)</code></pre><p>This creates a model with the &quot;simple pairwise&quot; structure, using a single association parameter. The default is to use no centering adjustment, and to use coding <span>$(-1,1)$</span> for the responses.  This &quot;symmetric&quot; version of the model is recommended for <a href="https://doi.org/10.3389/fams.2017.00024">a variety of reasons</a>.  Using different coding or centering choices is only recommended if you have a thorough understanding of what you are doing; but if you wish to use different choices, this can easily be done using keyword arguments. For example, <code>ALRsimple(G, X, Y=Y, coding=(0,1), centering=expectation)</code> creates the &quot;centered autologistic model&quot; that has appeared in the literature, e.g. <a href="https://link.springer.com/article/10.1198/jabes.2009.07032">here</a> and <a href="https://doi.org/10.1002/env.1102">here</a></p><p>The model has nine parameters (eight regression coefficients plus the association parameter).  All parameters are initialized to zero:</p><pre><code class="language-">getparameters(model)</code></pre><p>When we call <code>getparameters</code>, the vector returned always has the unary parameters first, with the pairwise parameter(s) appended at the end.</p><p>Because there are only two vertices in the graph, we can use the full likelihood (<code>fit_ml!</code> function) to do parameter estimation.  This function returns a structure with the estimates as well as standard errors, p-values, and 95% confidence intervals for the  parameter estimates.</p><pre><code class="language-">out = fit_ml!(model)</code></pre><p>To view the estimation results, use <code>summary</code>:</p><pre><code class="language-">summary(out, parnames = [&quot;icept&quot;, &quot;aut_dom&quot;, &quot;aut_rec&quot;, &quot;sex_link&quot;, &quot;age&quot;, &quot;sex&quot;, 
        &quot;psc&quot;, &quot;eye&quot;, &quot;λ&quot;])</code></pre><p>From this we see that the association parameter is fairly large (0.818), supporting the idea that the left and right eyes are associated.  It is also highly statistically significant.  Among the covariates, <code>sex_link</code>, <code>age</code>, and <code>psc</code> are all statistically significant.</p><h2><a class="nav-anchor" id="Spatial-Binary-Regression-1" href="#Spatial-Binary-Regression-1">Spatial Binary Regression</a></h2><p>TODO.  Create the graph using spatialgraph and plot the endogenous probabilities (gplot); fit the ALRsimple model and do inference with parametric bootstrap; show how alternative models (e.g. centered ALR model) can be made and compared.  Show the estimated fitted probabilities of symmetric and centered models (and/or predicted probs for altitude=0?)</p><footer><hr/><a class="previous" href="../BasicUsage/"><span class="direction">Previous</span><span class="title">Basic Usage</span></a><a class="next" href="../api/"><span class="direction">Next</span><span class="title">Reference</span></a></footer></article></body></html>
